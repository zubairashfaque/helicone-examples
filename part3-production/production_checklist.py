"""
Production Checklist - All Best Practices Combined

This example demonstrates a production-ready LLM request with:
âœ… Session tracing
âœ… Caching
âœ… Rate limiting
âœ… Security scanning
âœ… User tracking
âœ… Custom properties
âœ… Retry + fallback
âœ… PostHog integration
"""

from openai import OpenAI
import os
from dotenv import load_dotenv
import uuid

load_dotenv()

client = OpenAI(
    base_url="https://ai-gateway.helicone.ai",
    api_key=os.getenv("HELICONE_API_KEY"),
)

# Production-ready request with full instrumentation
session_id = str(uuid.uuid4())

response = client.chat.completions.create(
    model="gpt-4o-mini/claude-sonnet-4",  # Primary + fallback
    messages=[
        {"role": "system", "content": "You are a helpful medical AI assistant."},
        {"role": "user", "content": "What are the symptoms of Type 2 diabetes?"}
    ],
    max_tokens=300,
    temperature=0,
    extra_headers={
        # Session Tracing
        "Helicone-Session-Id": session_id,
        "Helicone-Session-Path": "/production/medical-query",

        # User Tracking
        "Helicone-User-Id": "user_12345",

        # Custom Properties (for filtering and analytics)
        "Helicone-Property-Environment": "production",
        "Helicone-Property-Feature": "medical-assistant",
        "Helicone-Property-Version": "v2.1.0",
        "Helicone-Property-Department": "healthcare",

        # Caching
        "Helicone-Cache-Enabled": "true",
        "Cache-Control": "max-age=3600",

        # Rate Limiting (100 requests/hour per user)
        "Helicone-RateLimit-Policy": "100;w=3600;s=user",

        # Security Scanning
        "Helicone-LLM-Security-Enabled": "true",
        "Helicone-Prompt-Guard-Enabled": "true",

        # Retry + Fallback
        "Helicone-Retry-Enabled": "true",
        "Helicone-Retry-Num": "3",
        "Helicone-Retry-Factor": "2",
        "Helicone-Fallback-Enabled": "true",

        # Prompt Versioning
        "Helicone-Prompt-Id": "medical-query-v2",

        # PostHog Integration (optional)
        # "Helicone-PostHog-Key": os.getenv("POSTHOG_API_KEY"),
        # "Helicone-PostHog-Event": "medical_query_completed",
    }
)

print("âœ… Production Request Complete!")
print(f"   Session ID: {session_id}")
print(f"   Response: {response.choices[0].message.content[:100]}...")
print()
print("ðŸ“Š Production Features Enabled:")
print("   âœ“ Session tracing (hierarchical path)")
print("   âœ“ Semantic caching (1-hour TTL)")
print("   âœ“ Per-user rate limiting (100 req/hour)")
print("   âœ“ Security scanning (Llama Guard + Prompt Guard)")
print("   âœ“ Automatic retries with exponential backoff")
print("   âœ“ Cross-provider fallback (GPT-4o â†’ Claude)")
print("   âœ“ Prompt version tracking")
print("   âœ“ Custom properties for analytics")
print()
print("ðŸŽ¯ Production Readiness Score: 100%")
